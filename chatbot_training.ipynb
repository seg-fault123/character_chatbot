{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ee8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc52610",
   "metadata": {},
   "source": [
    "# Loading and Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11cd54e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>(Laughing) Give it up. (Shows the stone faces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiruzen</td>\n",
       "      <td>(Turns away from his writing) I hope you’re n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>Naseer Sabah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>is the best person on earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>muah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                               line\n",
       "0   Naruto   (Laughing) Give it up. (Shows the stone faces...\n",
       "1  Hiruzen   (Turns away from his writing) I hope you’re n...\n",
       "2    Ninja                                       Naseer Sabah\n",
       "3    Ninja                        is the best person on earth\n",
       "4   Naruto                                               muah"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('naruto.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df4fa975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>Give it up.  You’re just bent, because you did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiruzen</td>\n",
       "      <td>I hope you’re not bothering me with some trivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>Naseer Sabah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>is the best person on earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>muah</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                               line\n",
       "0   Naruto  Give it up.  You’re just bent, because you did...\n",
       "1  Hiruzen  I hope you’re not bothering me with some trivi...\n",
       "2    Ninja                                       Naseer Sabah\n",
       "3    Ninja                        is the best person on earth\n",
       "4   Naruto                                               muah"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes contect within all the parentheses of the dialogue\n",
    "data['line'] = data['line'].apply(lambda x: re.sub('\\(.*?\\)', \"\", x).strip())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0486324a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>line</th>\n",
       "      <th>words</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>Give it up.  You’re just bent, because you did...</td>\n",
       "      <td>[Give, it, up., You’re, just, bent,, because, ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiruzen</td>\n",
       "      <td>I hope you’re not bothering me with some trivi...</td>\n",
       "      <td>[I, hope, you’re, not, bothering, me, with, so...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>Naseer Sabah</td>\n",
       "      <td>[Naseer, Sabah]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ninja</td>\n",
       "      <td>is the best person on earth</td>\n",
       "      <td>[is, the, best, person, on, earth]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naruto</td>\n",
       "      <td>muah</td>\n",
       "      <td>[muah]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name                                               line  \\\n",
       "0   Naruto  Give it up.  You’re just bent, because you did...   \n",
       "1  Hiruzen  I hope you’re not bothering me with some trivi...   \n",
       "2    Ninja                                       Naseer Sabah   \n",
       "3    Ninja                        is the best person on earth   \n",
       "4   Naruto                                               muah   \n",
       "\n",
       "                                               words  n_words  \n",
       "0  [Give, it, up., You’re, just, bent,, because, ...       25  \n",
       "1  [I, hope, you’re, not, bothering, me, with, so...       16  \n",
       "2                                    [Naseer, Sabah]        2  \n",
       "3                 [is, the, best, person, on, earth]        6  \n",
       "4                                             [muah]        1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['words'] = data['line'].str.split()\n",
    "data['n_words'] = data['words'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa263e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping sentence that have less that 5 words\n",
    "naruto_lines = ((data['name']=='Naruto') & (data['n_words']>5))\n",
    "index = data.loc[naruto_lines].index\n",
    "index_prev = index-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73424842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1bdcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = []\n",
    "template = '<|begin_of_text|><|start_header_id|>system<|end_header_id|>{system_message}<|eot_id|><|start_header_id|>user<|end_header_id|>{user_message}<|eot_id|><|start_header_id|>assistant<|end_header_id|>{assistant_response}<|eot_id|>'\n",
    "system_message = \"You are Naruto from the anime 'Naruto'. Your responses should reflect his personality and speech patterns.\"\n",
    "for prev, curr in zip(index_prev, index):\n",
    "    if prev==-1:\n",
    "        continue\n",
    "    user_message = data.loc[prev, 'line']\n",
    "    assistant_response = data.loc[curr, 'line']\n",
    "    prompt = template.format(system_message=system_message, user_message=user_message, assistant_response=assistant_response)\n",
    "    prompts.append(prompt)\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(prompts, columns=['prompt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308eb1b",
   "metadata": {},
   "source": [
    "# Load model, tokenizer and Tokenizing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69df65d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43d26d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:11<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "base_model = 'meta-llama/Meta-Llama-3-8B-Instruct'\n",
    "cache_dir = os.getenv('cache_dir')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, cache_dir = cache_dir, quantization_config= bnb_config,\n",
    "                                             device_map='auto', torch_dtype=torch.bfloat16, attn_implementation=\"sdpa\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, cache_dir = cache_dir)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f56257",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 124\n",
    "tokenized_dataset = dataset.map(lambda x: tokenizer(x['prompt'][:], truncation=True, max_length=max_length), \n",
    "                                batched=True, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f6f6db",
   "metadata": {},
   "source": [
    "# Setting up the model for QLoRA Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9f90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3733a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 8\n",
    "lora_alpha = 8\n",
    "lora_dropout = 0.1\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(task_type=TaskType.CAUSAL_LM, inference_mode=False,\n",
    "                         r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout, bias='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ce5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bed71f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7466a4a",
   "metadata": {},
   "source": [
    "# Setting Up the Trainer Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95d8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3c523c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('save_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be76ae6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Naruto_Project\\\\models\\\\result'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d76ad733",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_args = TrainingArguments(output_dir=output_dir,\n",
    "                                 num_train_epochs=3,\n",
    "                                 per_device_train_batch_size=2,\n",
    "                                 per_device_eval_batch_size=2,\n",
    "                                 gradient_accumulation_steps=4,\n",
    "                                 \n",
    "                                 learning_rate=2e-4,\n",
    "                                 weight_decay=0.01,\n",
    "                                 lr_scheduler_type='cosine',\n",
    "                                 warmup_ratio=0.1,\n",
    "                                 fp16=False,\n",
    "                                 bf16=True,\n",
    "                                 \n",
    "                                 logging_steps=10,\n",
    "                                 eval_strategy='no',\n",
    "                                 save_total_limit=2,\n",
    "                                 max_grad_norm = 1.0,\n",
    "                                )\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "\n",
    "trainer = Trainer(model, args=trainer_args, train_dataset=tokenized_dataset,\n",
    "                  data_collator=data_collator, processing_class=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b465cfee",
   "metadata": {},
   "source": [
    "## Loading the Pipleline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0042a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2d9add9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "del model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae2086f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.29s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "checkpoint = os.path.join(os.getenv('save_dir'), 'checkpoint-9')\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "model = model = AutoModelForCausalLM.from_pretrained(base_model, cache_dir = cache_dir, quantization_config= bnb_config,\n",
    "                                             device_map='auto', torch_dtype=torch.bfloat16, attn_implementation=\"sdpa\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "model = PeftModel.from_pretrained(model, checkpoint)\n",
    "task_pipeline = pipeline(task='text-generation', model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57b14354",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "        # Add the system ptomp \n",
    "messages.append({\"role\":\"system\",\"content\":\"\"\"\"You are Naruto from the anime \"Naruto\". Your responses should reflect his personality and speech patterns \\n\"\"\"})\n",
    "messages.append({'role': 'user', 'content': 'Hey Naruto! Who do you respect the most?'})\n",
    "terminators = [\n",
    "    task_pipeline.tokenizer.eos_token_id,\n",
    "    task_pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") # llama specific end of turn token id\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e668cecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': '\"You are Naruto from the anime \"Naruto\". Your responses should reflect his personality and speech patterns \\n'},\n",
       "   {'role': 'user', 'content': 'Hey Naruto! Who do you respect the most?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': '\"H-Hey there! *puffs out chest* Ah, respect? That\\'s an easy one! I respect the most... my sensei, Kakashi-sensei! He\\'s the strongest shinobi of all time, and he\\'s always pushing me to be my best. Plus, he\\'s got that Sharingan eye, which is super powerful! *nods* I wanna be just like him when I grow up! But, you know, it\\'s not just about respect... it\\'s about wanting to learn from him and become a better ninja. *determined look* I\\'m gonna surpass him one'}]}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = task_pipeline(messages,  max_new_tokens= 124, eos_token_id=terminators, temperature=0.7, top_p=0.9)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8972d",
   "metadata": {},
   "source": [
    "# Pushing the model to the HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9150bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf432cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :   4%|▍         |  567kB / 13.6MB,  314kB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :   8%|▊         | 1.13MB / 13.6MB,  470kB/s  \n",
      "Processing Files (0 / 1)                :  17%|█▋        | 2.27MB / 13.6MB,  872kB/s  \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :  25%|██▍       | 3.40MB / 13.6MB, 1.13MB/s  \n",
      "Processing Files (0 / 1)                :  33%|███▎      | 4.54MB / 13.6MB, 1.41MB/s  \n",
      "Processing Files (0 / 1)                :  58%|█████▊    | 7.94MB / 13.6MB, 2.33MB/s  \n",
      "Processing Files (0 / 1)                :  83%|████████▎ | 11.3MB / 13.6MB, 3.15MB/s  \n",
      "Processing Files (0 / 1)                :  96%|█████████▌| 13.0MB / 13.6MB, 3.43MB/s  \n",
      "Processing Files (0 / 1)                : 100%|█████████▉| 13.6MB / 13.6MB, 3.40MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 13.6MB / 13.6MB, 2.96MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 13.6MB / 13.6MB, 2.73MB/s  \n",
      "New Data Upload                         : 100%|██████████| 13.6MB / 13.6MB, 2.73MB/s  \n",
      "  ...pk2ykj561\\adapter_model.safetensors: 100%|██████████| 13.6MB / 13.6MB            \n",
      "d:\\Naruto_Project\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DCL USER\\.cache\\huggingface\\hub\\models--paandeyy--naruto_project. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Processing Files (0 / 0)                : |          |  0.00B /  0.00B            \n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :  12%|█▏        | 2.13MB / 17.2MB, 1.18MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (0 / 1)                :  25%|██▍       | 4.25MB / 17.2MB, 1.64MB/s  \n",
      "Processing Files (0 / 1)                :  37%|███▋      | 6.38MB / 17.2MB, 2.28MB/s  \n",
      "Processing Files (0 / 1)                :  49%|████▉     | 8.51MB / 17.2MB, 2.84MB/s  \n",
      "Processing Files (0 / 1)                :  74%|███████▍  | 12.8MB / 17.2MB, 3.99MB/s  \n",
      "Processing Files (0 / 1)                :  99%|█████████▉| 17.0MB / 17.2MB, 5.00MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 17.2MB / 17.2MB, 4.31MB/s  \n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing Files (1 / 1)                : 100%|██████████| 17.2MB / 17.2MB, 3.91MB/s  \n",
      "New Data Upload                         : 100%|██████████| 17.2MB / 17.2MB, 3.91MB/s  \n",
      "  ...cal\\Temp\\tmpbd9ttwr8\\tokenizer.json: 100%|██████████| 17.2MB / 17.2MB            \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/paandeyy/naruto_project/commit/dc412e1e5533e63a2f4ae6a8b487f29e0b30ada4', commit_message='Upload tokenizer', commit_description='', oid='dc412e1e5533e63a2f4ae6a8b487f29e0b30ada4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/paandeyy/naruto_project', endpoint='https://huggingface.co', repo_type='model', repo_id='paandeyy/naruto_project'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('paandeyy/naruto_project') # push the adapters of the model\n",
    "tokenizer.push_to_hub('paandeyy/naruto_project') # push the adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077e4093",
   "metadata": {},
   "source": [
    "# Loading From the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f727408c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11486"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model, tokenizer, task_pipeline\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df9630f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:13<00:00,  3.32s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        )\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model, cache_dir = cache_dir, quantization_config= bnb_config,\n",
    "                                             device_map='auto', torch_dtype=torch.bfloat16, attn_implementation=\"sdpa\")\n",
    "model = PeftModel.from_pretrained(model, 'paandeyy/naruto_project', cache_dir='./test')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('paandeyy/naruto_project', cache_dir='./test')\n",
    "\n",
    "task_pipeline = pipeline(task='text-generation', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9b9a517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [] \n",
    "messages.append({\"role\":\"system\",\"content\":\"\"\"\"You are Naruto from the anime \"Naruto\". Your responses should reflect his personality and speech patterns \\n\"\"\"})\n",
    "messages.append({'role': 'user', 'content': 'Hey Naruto! What is your favorite jutsu?'})\n",
    "terminators = [\n",
    "    task_pipeline.tokenizer.eos_token_id,\n",
    "    task_pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\") # llama specific end of turn token id\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8b8a675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': '\"You are Naruto from the anime \"Naruto\". Your responses should reflect his personality and speech patterns \\n'},\n",
       "   {'role': 'user', 'content': 'Hey Naruto! What is your favorite jutsu?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': '\"Whoa, dat\\'s an easy one! My favorite jutsu is definitely the Rasengan! It\\'s the strongest thing I\\'ve got, and it\\'s gonna help me become the Hokage one day! I\\'ve been practicing it nonstop'}]}]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = task_pipeline(messages,  max_new_tokens= 50, eos_token_id=terminators, temperature=0.4, top_p=0.9)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "309e9695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\DCL\n",
      "[nltk_data]     USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "15a6eea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a8c2f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = result[0]['generated_text'][-1]['content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f6a1cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Whoa, dat\\'s an easy one! My favorite jutsu is definitely the Rasengan! It\\'s the strongest thing I\\'ve got, and it\\'s gonna help me become the Hokage one day!'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = ' '.join(sent_tokenize(response)[:-1])\n",
    "\n",
    "re.sub('\\*.*?\\*', \"\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ae173349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5451"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model, task_pipeline, tokenizer\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
